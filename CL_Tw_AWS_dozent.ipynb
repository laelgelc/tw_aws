{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "810d9f10-ec19-4b09-8f90-e983e460b319",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://laelgelcpublic.s3.sa-east-1.amazonaws.com/lael_50_years_narrow_white.png.no_years.400px_96dpi.png\" width=\"300\" alt=\"LAEL 50 years logo\">\n",
    "<h3>APPLIED LINGUISTICS GRADUATE PROGRAMME (LAEL)</h3>\n",
    "</center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888c2c96-2fc3-4a1a-995b-c388036a2a15",
   "metadata": {},
   "source": [
    "# 'The Twitter Stream Grab' download and storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9c2af7-9fc1-4f51-a4f5-2ed915b93039",
   "metadata": {},
   "source": [
    "## Updating ['dozent'](https://github.com/Social-Media-Public-Analysis/dozent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5d9541-09da-4983-adc8-3d7bda75e71e",
   "metadata": {},
   "source": [
    "Dozent is a powerful downloader that is used to collect large amounts of Twitter data from the Internet Archive.\n",
    "\n",
    "It had been maintained until 30th June, 2020, but the 'Twitter Stream Grab' on the Internet Archive contains data up to 30th January, 2023.\n",
    "\n",
    "There is a file in Dozent's code named 'twitter-archive-stream-links.json' which listed the links to the dataset's archives and which had to be updated to support downloads up to 30th January, 2023.\n",
    "\n",
    "A list of links, considering the content on the Internet Archive up to 30th January, 2023, was manually compiled and then processed to obtain an updated version of 'twitter-archive-stream-links.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551ea9f6-03fa-444d-882b-1ed6f56183f0",
   "metadata": {},
   "source": [
    "### Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84db29bd-a60d-4a8d-ac1a-e745d3a101d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057e99e9-d550-4134-b511-f2a52cf1e734",
   "metadata": {},
   "source": [
    "### Determining the patterns of the links\n",
    "- Processing 'links.txt' to obtain 'twitter-archive-stream-links.json' requires that 'day', 'month' and 'year' are retrieved from each link. Thus, it is required to determine the patterns of the links\n",
    "- 'links.txt' was sorted and the resulting 'sorted_links.txt' was inspected with VS Code to identify the patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abbe793-5faa-4600-a0f5-96169713794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original_links = pd.read_table('links.txt', sep='\\\\n', header=None, engine='python')\n",
    "df_original_links = df_original_links.replace(' \\(View Contents\\).*$', '', regex=True).replace('\t08-Jun-2014 16:46\t5.2G.*$', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a791049-7f9a-445b-8f8e-8c130cdf9ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted_links = df_original_links.sort_values(0, ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331ffa0c-0559-4248-a085-93dd23dad8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted_links.to_csv('sorted_links.txt', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4079855f-ba4a-4ab2-93c9-b2a7f9047431",
   "metadata": {},
   "source": [
    "### Formatting 'twitter-archive-stream-links.json' from 'links.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbaf32a-c145-41c6-bbb6-fa11b5347c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_links(input_file):\n",
    "    df = pd.DataFrame(columns=['day', 'month', 'year', 'link'])\n",
    "    df['link'] = pd.read_table(input_file, sep='\\\\n', header=None, engine='python')\n",
    "    df['link'] = df['link'].replace(' \\(View Contents\\).*$', '', regex=True).replace('\t08-Jun-2014 16:46\t5.2G.*$', '', regex=True)\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        if row['link'].startswith('https://archive.org/download/archiveta'):\n",
    "            year = row['link'][80:84]\n",
    "            month = row['link'][84:86]\n",
    "            day = row['link'][86:88]\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-json-twitterstream-2012/twitter-stream-2012-01-'):\n",
    "            year = row['link'][80:84]\n",
    "            month = row['link'][85:87]\n",
    "            day = row['link'][88:90]\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-json-twitterstream/twitter-stream-2011-'):\n",
    "            year = row['link'][75:79]\n",
    "            month = row['link'][80:82]\n",
    "            day = row['link'][83:85]\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-json-2011/twitter-json-scrape-2011-'):\n",
    "            year = row['link'][79:83]\n",
    "            month = row['link'][84:86]\n",
    "            day = 'NaN'\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2012-'):\n",
    "            year = row['link'][84:88]\n",
    "            month = row['link'][89:91]\n",
    "            day = 'NaN'\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2013-'):\n",
    "            year = row['link'][91:95]\n",
    "            month = row['link'][96:98]\n",
    "            day = 'NaN'\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2014-'):\n",
    "            year = row['link'][91:95]\n",
    "            month = row['link'][96:98]\n",
    "            day = 'NaN'\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2015-'):\n",
    "            year = row['link'][91:95]\n",
    "            month = row['link'][96:98]\n",
    "            day = 'NaN'\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2016-'):\n",
    "            year = row['link'][91:95]\n",
    "            month = row['link'][96:98]\n",
    "            day = 'NaN'\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2017-01'):\n",
    "            year = row['link'][91:95]\n",
    "            month = row['link'][96:98]\n",
    "            day = 'NaN'\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2017-02'):\n",
    "            year = row['link'][91:95]\n",
    "            month = row['link'][96:98]\n",
    "            day = 'NaN'\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2017-03'):\n",
    "            year = row['link'][91:95]\n",
    "            month = row['link'][96:98]\n",
    "            day = 'NaN'\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2017-04'):\n",
    "            year = row['link'][91:95]\n",
    "            month = row['link'][96:98]\n",
    "            day = 'NaN'\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2017-05'):\n",
    "            year = row['link'][91:95]\n",
    "            month = row['link'][96:98]\n",
    "            day = 'NaN'\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2017-06'):\n",
    "            year = row['link'][91:95]\n",
    "            month = row['link'][96:98]\n",
    "            day = 'NaN'\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year    \n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2017-07'):\n",
    "            year = row['link'][79:83]\n",
    "            month = row['link'][84:86]\n",
    "            day = row['link'][87:89]\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2017-08'):\n",
    "            year = row['link'][79:83]\n",
    "            month = row['link'][84:86]\n",
    "            day = row['link'][87:89]\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2017-09'):\n",
    "            year = row['link'][79:83]\n",
    "            month = row['link'][84:86]\n",
    "            day = row['link'][87:89]\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2017-10'):\n",
    "            year = row['link'][79:83]\n",
    "            month = row['link'][84:86]\n",
    "            day = row['link'][87:89]\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2017-11'):\n",
    "            year = row['link'][79:83]\n",
    "            month = row['link'][84:86]\n",
    "            day = row['link'][87:89]\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2018-01'):\n",
    "            year = row['link'][91:95]\n",
    "            month = row['link'][96:98]\n",
    "            day = 'NaN'\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2018-02'):\n",
    "            year = row['link'][91:95]\n",
    "            month = row['link'][96:98]\n",
    "            day = 'NaN'\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2018-03'):\n",
    "            year = row['link'][91:95]\n",
    "            month = row['link'][96:98]\n",
    "            day = 'NaN'\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2018-04'):\n",
    "            year = row['link'][91:95]\n",
    "            month = row['link'][96:98]\n",
    "            day = 'NaN'\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2018-05'):\n",
    "            year = row['link'][72:76]\n",
    "            month = row['link'][77:79]\n",
    "            day = row['link'][80:82]\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2018-06'):\n",
    "            year = row['link'][72:76]\n",
    "            month = row['link'][77:79]\n",
    "            day = row['link'][80:82]\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2018-07'):\n",
    "            year = row['link'][72:76]\n",
    "            month = row['link'][77:79]\n",
    "            day = row['link'][80:82]\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year    \n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2018-08'):\n",
    "            year = row['link'][72:76]\n",
    "            month = row['link'][77:79]\n",
    "            day = row['link'][80:82]\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2018-09'):\n",
    "            year = row['link'][72:76]\n",
    "            month = row['link'][77:79]\n",
    "            day = row['link'][80:82]\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2018-10/twitter-2018'):\n",
    "            year = row['link'][72:76]\n",
    "            month = row['link'][77:79]\n",
    "            day = row['link'][80:82]\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2018-10/twitter_'):\n",
    "            year = row['link'][79:83]\n",
    "            month = row['link'][84:86]\n",
    "            day = row['link'][87:89]\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2018-11'):\n",
    "            year = row['link'][79:83]\n",
    "            month = row['link'][84:86]\n",
    "            day = row['link'][87:89]\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2018-12'):\n",
    "            year = row['link'][79:83]\n",
    "            month = row['link'][84:86]\n",
    "            day = row['link'][87:89]\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2019'):\n",
    "            year = row['link'][79:83]\n",
    "            month = row['link'][84:86]\n",
    "            day = row['link'][87:89]\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2020'):\n",
    "            year = row['link'][79:83]\n",
    "            month = row['link'][84:86]\n",
    "            day = row['link'][87:89]\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year    \n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2021-01'):\n",
    "            year = row['link'][79:83]\n",
    "            month = row['link'][84:86]\n",
    "            day = row['link'][87:89]\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2021-02'):\n",
    "            year = row['link'][79:83]\n",
    "            month = row['link'][84:86]\n",
    "            day = row['link'][87:89]\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2021-03'):\n",
    "            year = row['link'][79:83]\n",
    "            month = row['link'][84:86]\n",
    "            day = row['link'][87:89]\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2021-04'):\n",
    "            year = row['link'][79:83]\n",
    "            month = row['link'][84:86]\n",
    "            day = row['link'][87:89]\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2021-05'):\n",
    "            year = row['link'][79:83]\n",
    "            month = row['link'][84:86]\n",
    "            day = row['link'][87:89]\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2021-06'):\n",
    "            year = row['link'][79:83]\n",
    "            month = row['link'][84:86]\n",
    "            day = row['link'][87:89]\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2021-07'):\n",
    "            year = row['link'][79:83]\n",
    "            month = row['link'][84:86]\n",
    "            day = row['link'][87:89]\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2021-08/twitter-stream-2021-'):\n",
    "            year = row['link'][79:83]\n",
    "            month = row['link'][84:86]\n",
    "            day = row['link'][87:89]\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year    \n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2021-08/twitter-stream-20210'):\n",
    "            year = row['link'][79:83]\n",
    "            month = row['link'][83:85]\n",
    "            day = row['link'][85:87]\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2021-09'):\n",
    "            year = row['link'][79:83]\n",
    "            month = row['link'][83:85]\n",
    "            day = row['link'][85:87]\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2021-10'):\n",
    "            year = row['link'][79:83]\n",
    "            month = row['link'][83:85]\n",
    "            day = row['link'][85:87]\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2021-11'):\n",
    "            year = row['link'][79:83]\n",
    "            month = row['link'][83:85]\n",
    "            day = row['link'][85:87]\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2021-12'):\n",
    "            year = row['link'][79:83]\n",
    "            month = row['link'][83:85]\n",
    "            day = row['link'][85:87]\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2022'):\n",
    "            year = row['link'][79:83]\n",
    "            month = row['link'][83:85]\n",
    "            day = row['link'][85:87]\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "        elif row['link'].startswith('https://archive.org/download/archiveteam-twitter-stream-2023'):\n",
    "            year = row['link'][79:83]\n",
    "            month = row['link'][83:85]\n",
    "            day = row['link'][85:87]\n",
    "            df.at[index, 'day'] = day\n",
    "            df.at[index, 'month'] = month\n",
    "            df.at[index, 'year'] = year\n",
    "    \n",
    "    return df\n",
    "\n",
    "input_file = 'links.txt'\n",
    "df_links = format_links(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9aa6a2-223d-44a1-9ca1-5078b5936ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab54bda-df46-4626-a3a0-f49c2738f8c0",
   "metadata": {},
   "source": [
    "### Generating the formatted 'json' file for 'dozent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04d69b3-d25d-40f9-83c0-1a098a33ebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'twitter-archive-stream-links-updated.json'\n",
    "df_links.to_json(output_file, orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9126ae-8309-4336-aadf-2e2e5631950e",
   "metadata": {},
   "source": [
    "### Formatting the resulting 'json' file\n",
    "- The resulting 'twitter-archive-stream-links-updated.json' file must be formatted with [JSON formatter](https://jsonformatter.org) considering a two-space tab and renamed to 'twitter-archive-stream-links.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7f1cef-b4f5-4387-9ae7-73f381ad5e95",
   "metadata": {},
   "source": [
    "### Debugging 'twitter-archive-stream-links.json'\n",
    "- Malformed dates were detected in the following lines and manually corrected as follows:\n",
    "  - Line 1575: from '31/09/2017' to '30/09/2017'\n",
    "  - Line 1947: from '31/11/2017' to '30/11/2017'\n",
    "  - Line 5985: from '31/04/2020' to '30/04/2020'\n",
    "  - Line 6357: from '31/06/2020' to '30/06/2020'\n",
    "\n",
    "Note: Those malformed dates were causing the programme to break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6983c63-ff6d-4242-9a29-43c6635e02b0",
   "metadata": {},
   "source": [
    "## Running 'dozent'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b7baca-128b-4a34-8b41-07c77323175a",
   "metadata": {},
   "source": [
    "'dozent' is going to be run as part of a programme named 'tw_aws_dozent.py'\n",
    " - The code of 'tw_aws_dozent.py' is indicated as follows\n",
    " - It should be placed in '/home/ubuntu/{env}/' directory, where {env} corresponds to the virtual environment where 'dozent' is deployed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7602d6cf-99ab-4942-8835-ad717df630e6",
   "metadata": {},
   "source": [
    "### There are two possibilities of execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca17a1fd-f5c5-4dbe-9c18-4967db1f175a",
   "metadata": {},
   "source": [
    "#### On the terminal\n",
    "The terminal should remain open all the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79571795-ccc7-4693-9aeb-a593266dcb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "(my_env) ubuntu@ip-172-31-16-95:~/my_env$ python tw_aws_dozent.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb5a1e0-03d3-45f1-8b57-b80126c78625",
   "metadata": {},
   "source": [
    "#### In the background\n",
    "The programme will be executed in the background even if the terminal session is closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f85e59-5de9-421b-9088-9d8cc184bb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "(my_env) ubuntu@ip-172-31-16-95:~/my_env$ nohup python tw_aws_dozent.py &\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab0b9cd-0950-4f4c-8e06-a4e8cf91a129",
   "metadata": {},
   "source": [
    "### Code of 'tw_aws_dozent.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becb967a-635b-42ed-988b-e9194125585e",
   "metadata": {},
   "source": [
    "- 'tw_aws_dozent.py' requires 'pandas'. This prerequisite should be met in the deployment of the virtual environment\n",
    "- 'date_list' should contain the filename of the required batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8930cd1f-a08d-4c74-9820-089924f79683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "date_list = 'tw_aws_dozent_date_list_test.csv'\n",
    "#date_list = 'tw_aws_dozent_date_list_2011.csv'\n",
    "#date_list = 'tw_aws_dozent_date_list_2012.csv'\n",
    "#date_list = 'tw_aws_dozent_date_list_2013.csv'\n",
    "#date_list = 'tw_aws_dozent_date_list_2014.csv'\n",
    "#date_list = 'tw_aws_dozent_date_list_2015.csv'\n",
    "#date_list = 'tw_aws_dozent_date_list_2016.csv'\n",
    "#date_list = 'tw_aws_dozent_date_list_2017.csv'\n",
    "#date_list = 'tw_aws_dozent_date_list_2018.csv'\n",
    "#date_list = 'tw_aws_dozent_date_list_2019.csv'\n",
    "#date_list = 'tw_aws_dozent_date_list_2020.csv'\n",
    "#date_list = 'tw_aws_dozent_date_list_2021.csv'\n",
    "#date_list = 'tw_aws_dozent_date_list_2022.csv'\n",
    "#date_list = 'tw_aws_dozent_date_list_2023.csv'\n",
    "#date_list = 'tw_aws_dozent_date_list_test.csv'\n",
    "\n",
    "env = 'my_env'\n",
    "bucket = 'laelgelctweets'\n",
    "\n",
    "origin = '/home/ubuntu/{}/lib/python3.10/site-packages/data/*'.format(env)\n",
    "destination = 's3://{}/'.format(bucket)\n",
    "logfile = 'tw_aws_dozent.log'\n",
    "df = pd.read_csv(date_list, header = 0)\n",
    "\n",
    "with open(logfile, 'a', encoding='utf8') as log:\n",
    "    for index, row in df.iterrows():\n",
    "        date = row['Dates']\n",
    "        print('Processing ' + date)\n",
    "        log.write('Processing ' + date + '\\n')\n",
    "        subprocess.run(['python', '-m', 'dozent', '-s', date, '-e', date], bufsize=0)\n",
    "        files_to_copy = glob.glob(origin)\n",
    "        for file in files_to_copy:\n",
    "            subprocess.run(['aws', 's3', 'cp', file, destination], bufsize=0)\n",
    "            subprocess.run(['rm', '-f', file], bufsize=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6a9fbe-8c94-4fc2-bea1-48317f239ba4",
   "metadata": {},
   "source": [
    "## Alternative solution via 'pySmartDL'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8058a8-a460-49bd-9cf5-dc64669ee64c",
   "metadata": {},
   "source": [
    "- 'pySmartDL' is the heart of 'dozent'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d166f50-97e2-4944-aeb4-fe776a1fc5e7",
   "metadata": {},
   "source": [
    "### Code of 'tw_aws_pysmartdl.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fcfd0bb-63fd-43b2-95c8-98200b84ac27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old output directory successfully removed.\n",
      "Output directory successfully created.\n"
     ]
    }
   ],
   "source": [
    "#from pySmartDL import SmartDL\n",
    "#import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "output_directory = 'data'\n",
    "\n",
    "if os.path.exists(output_directory):\n",
    "    shutil.rmtree(output_directory)\n",
    "    print('Old output directory successfully removed.')\n",
    "    try:\n",
    "        os.makedirs(output_directory)\n",
    "        print('Output directory successfully created.')\n",
    "    except OSError as e:\n",
    "        print('Failed to create the directory:', e)\n",
    "        sys.exit(1)\n",
    "else:\n",
    "    try:\n",
    "        os.makedirs(output_directory)\n",
    "        print('Output directory successfully created.')\n",
    "    except OSError as e:\n",
    "        print('Failed to create the directory:', e)\n",
    "        sys.exit(1)\n",
    "            \n",
    "#url = \"https://archive.org/download/archiveteam-json-twitterstream/twitter-stream-2011-09-27.zip\"\n",
    "#dest = \"/home/ubuntu/my_env/smartdl\" # or '~/Downloads/' on linux\n",
    "\n",
    "#obj = SmartDL(url, dest)\n",
    "#obj.start()\n",
    "# [*] 0.23 Mb / 0.37 Mb @ 88.00Kb/s [##########--------] [60%, 2s left]\n",
    "\n",
    "#path = obj.get_dest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c2c5fe-7a39-4faf-b67c-5f719d2888da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b376c693-32c4-45ad-9ebe-406f9a82182d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
